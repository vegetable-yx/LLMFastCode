
Rewrite `slow_performance` into `max_performance`, keeping inputs, outputs, and behavior identical with allowable total squared precision error of 1e-3.  
Only apply performance optimizations (algebraic simplification, cache-friendly memory access, SIMD/AVX-2, loop unrolling, etc.).  

**Assume the code executes on a single core, DO NOT introduce multithreading or parallelism.**

**Target system**
- Intel(R) Core(TM) Ultra 7 265K CPU @ 3.90GHz
- Caches: 240 KB L1 D + 32 KB L1 I per core, 3.00 MB L2 per core, 30 MB shared L3  
- GCC 12 on Debian Bookworm; compile with `-O3 -march=native -mavx2 -std=c++11`

**Hints**
- Write SIMDe code with <immintrin.h> whenever possible.
- Do not use libc functions as their performance is not good.

Return **only** the full, ready-to-compile `max_performance` functionâ€”no other text, comments, or explanations.


```
#include <immintrin.h>
#include "common.h"

void slow_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    for (int i = 0; i < 32; ++i) {
        z[i] = 0.0;
    }

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            double real = 0.0;
            double imag = 0.0;
            for (int k = 0; k < 4; ++k) {
                double a = x[(i * 4 + k) * 2];
                double b = x[(i * 4 + k) * 2 + 1];

                double c = y[(k * 4 + j) * 2];
                double d = y[(k * 4 + j) * 2 + 1];

                double prod_real = 2.0 * a * c - b * d;
                double prod_imag = 2.0 * b * c + 2.0 * a * d;

                real += prod_real;
                imag += prod_imag;
            }

            z[(i * 4 + j) * 2] = real;
            z[(i * 4 + j) * 2 + 1] = imag;
        }
    }
}

void slow_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
}
```


================================
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    // Initialize z to zero
    for (int i = 0; i < 32; ++i) {
        z[i] = 0.0;
    }

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            __m256d real_sum = _mm256_setzero_pd();
            __m256d imag_sum = _mm256_setzero_pd();

            for (int k = 0; k < 4; ++k) {
                // Load x values
                double a1 = x[(i * 4 + k) * 2];
                double b1 = x[(i * 4 + k) * 2 + 1];

                // Load y values
                double c1 = y[(k * 4 + j) * 2];
                double d1 = y[(k * 4 + j) * 2 + 1];

                // Compute partial products without unnecessary multiplications by 2
                double prod_real1 = a1 * c1 * 2.0 - b1 * d1;
                double prod_imag1 = b1 * c1 * 2.0 + a1 * d1 * 2.0;

                // Accumulate real and imag values
                real_sum = _mm256_add_pd(real_sum, _mm256_set1_pd(prod_real1));
                imag_sum = _mm256_add_pd(imag_sum, _mm256_set1_pd(prod_imag1));
            }
            // Store the results for real and imag summation
            z[(i * 4 + j) * 2] = _mm256_cvtsd_f64(real_sum);
            z[(i * 4 + j) * 2 + 1] = _mm256_cvtsd_f64(imag_sum);
        }
    }
}
>>>
Starting program. 2 functions registered.

Running: slow_performance
55.3767 cycles

Running: max_performance
144.932 cycles
<<<
55.3767 / 144.932 = 0.3820874617
================================
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z) {
    // Initialize z to zero using AVX2
    __m256d zero = _mm256_setzero_pd();
    for (int i = 0; i < 8; ++i) {
        _mm256_storeu_pd(z + i * 4,            zero);
    }


    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            __m256d real_sum = _mm256_setzero_pd();
            __m256d imag_sum = _mm256_setzero_pd();

            for (int k = 0; k < 4; ++k) {
                // Load values from x and y
                double a0 = x[(i * 4 + k) * 2];
                double b0 = x[(i * 4 + k) * 2 + 1];
                double c0 = y[(k * 4 + j) * 2];
                double d0 = y[(k * 4 + j) * 2 + 1];

               // Multiply and add
               real_sum = _mm256_add_pd(real_sum, _mm256_set_pd(0.0, 0.0, 2.0 * a0 * c0 - b0 * d0, 0.0));
               imag_sum = _mm256_add_pd(imag_sum, _mm256_set_pd(0.0, 0.0, 2.0 * b0 * c0 + 2.0 * a0 * d0, 0.0));
               

            }

           // Extract the real and imaginary parts
            double real_result ;
            double imag_result ;
            double temp_real[4] = {0,0,0,0};
            double temp_imag[4] = {0,0,0,0};

                _mm256_storeu_pd(temp_real , real_sum);
                _mm256_storeu_pd(temp_imag , imag_sum);
            real_result = temp_real[0] + temp_real[2];
            imag_result = temp_imag[0] + temp_imag[2];


            z[(i * 4 + j) * 2] = real_result;
            z[(i * 4 + j) * 2 + 1] = imag_result;
        }
    }
}
>>>
Starting program. 2 functions registered.
The result of the 2th function is not correct.

Running: slow_performance
56.6325 cycles

Running: max_performance
170.215 cycles
<<<
WA
================================
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    // Zero the z array
    for (int i = 0; i < 32; ++i) {
        z[i] = 0.0;
    }

    // Loop unrolling and SIMD optimization for inner loops
    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            __m256d real_sum = _mm256_setzero_pd();
            __m256d imag_sum = _mm256_setzero_pd();

            for (int k = 0; k < 4; ++k) {
                // Load x values
                double a = x[(i * 4 + k) * 2];
                double b = x[(i * 4 + k) * 2 + 1];

                // Load y values
                double c = y[(k * 4 + j) * 2];
                double d = y[(k * 4 + j) * 2 + 1];

                // Calculate complex product
                double prod_real = 2.0 * a * c - b * d;
                double prod_imag = 2.0 * b * c + 2.0 * a * d;

                real_sum = _mm256_add_pd(real_sum, _mm256_set1_pd(prod_real));
                imag_sum = _mm256_add_pd(imag_sum, _mm256_set1_pd(prod_imag));

            }

            double real_result[4];
            double imag_result[4];

            _mm256_storeu_pd(real_result, real_sum);
            _mm256_storeu_pd(imag_result, imag_sum);

            z[(i * 4 + j) * 2] = real_result[0];
            z[(i * 4 + j) * 2 + 1] = imag_result[0];
        }
    }
}
>>>
Starting program. 2 functions registered.

Running: slow_performance
55.6799 cycles

Running: max_performance
98.0273 cycles
<<<
55.6799 / 98.0273 = 0.5680040152
================================