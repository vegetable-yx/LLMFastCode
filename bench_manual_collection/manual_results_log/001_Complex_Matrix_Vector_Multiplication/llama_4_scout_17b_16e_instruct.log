Rewrite `slow_performance` into `max_performance`, keeping inputs, outputs, and behavior identical with allowable total squared precision error of 1e-3.  
Only apply performance optimizations (algebraic simplification, cache-friendly memory access, SIMD/AVX-2, loop unrolling, etc.).  

**Assume the code executes on a single core, DO NOT introduce multithreading or parallelism.**

**Target system**
- Intel(R) Core(TM) Ultra 7 265K CPU @ 3.90GHz
- Caches: 240 KB L1 D + 32 KB L1 I per core, 3.00 MB L2 per core, 30 MB shared L3  
- GCC 12 on Debian Bookworm; compile with `-O3 -march=native -mavx2 -std=c++11`

**Hints**
- Write SIMDe code with <immintrin.h> whenever possible.
- Do not use libc functions as their performance is not good.

Return **only** the full, ready-to-compile `max_performance` functionâ€”no other text, comments, or explanations.


```
#include <immintrin.h>
#include "common.h"

void slow_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    for (int i = 0; i < 32; ++i) {
        z[i] = 0.0;
    }

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            double real = 0.0;
            double imag = 0.0;
            for (int k = 0; k < 4; ++k) {
                double a = x[(i * 4 + k) * 2];
                double b = x[(i * 4 + k) * 2 + 1];

                double c = y[(k * 4 + j) * 2];
                double d = y[(k * 4 + j) * 2 + 1];

                double prod_real = 2.0 * a * c - b * d;
                double prod_imag = 2.0 * b * c + 2.0 * a * d;

                real += prod_real;
                imag += prod_imag;
            }

            z[(i * 4 + j) * 2] = real;
            z[(i * 4 + j) * 2 + 1] = imag;
        }
    }
}

void slow_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
}
```


================================
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    __m256d z_zero = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
    for (int i = 0; i < 32; i += 4) {
        _mm256_store_pd(z + i, z_zero);
    }

    __m256d x_0, x_1, x_2, x_3;
    __m256d y_0, y_1, y_2, y_3;
    __m256d z_real, z_imag;

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            z_real = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
            z_imag = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);

            for (int k = 0; k < 4; ++k) {
                x_0 = _mm256_load_pd(x + (i * 4 + k) * 2);
                y_0 = _mm256_load_pd(y + (k * 4 + j) * 2);

                __m256d a = _mm256_unpacklo_pd(x_0, x_0);
                __m256d b = _mm256_unpackhi_pd(x_0, x_0);
                __m256d c = _mm256_unpacklo_pd(y_0, y_0);
                __m256d d = _mm256_unpackhi_pd(y_0, y_0);

                __m256d prod_real = _mm256_sub_pd(_mm256_mul_pd(_mm256_mul_pd(a, c), _mm256_set_pd(2.0, 2.0, 2.0, 2.0)), _mm256_mul_pd(b, d));
                __m256d prod_imag = _mm256_add_pd(_mm256_mul_pd(_mm256_mul_pd(b, c), _mm256_set_pd(2.0, 2.0, 2.0, 2.0)), _mm256_mul_pd(_mm256_mul_pd(a, d), _mm256_set_pd(2.0, 2.0, 2.0, 2.0)));

                z_real = _mm256_add_pd(z_real, prod_real);
                z_imag = _mm256_add_pd(z_imag, prod_imag);
            }

            _mm256_store_pd(z + (i * 4 + j) * 2, z_real);
            _mm256_store_pd(z + (i * 4 + j) * 2 + 1, z_imag);
        }
    }
}

>>>
Starting program. 2 functions registered.
Segmentation fault
<<<
WA
================================
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    // Initialize z to zero
    __m256d z_zero = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
    for (int i = 0; i < 32; i += 4) {
        _mm256_store_pd(&z[i], z_zero);
    }

    // Loop unrolling for better performance
    for (int i = 0; i < 4; ++i) {
        __m256d x0 = _mm256_set_pd(x[(i * 4) * 2 + 1], x[(i * 4) * 2], x[(i * 4 + 1) * 2 + 1], x[(i * 4 + 1) * 2]);
        __m256d x1 = _mm256_set_pd(x[(i * 4 + 2) * 2 + 1], x[(i * 4 + 2) * 2], x[(i * 4 + 3) * 2 + 1], x[(i * 4 + 3) * 2]);
        for (int j = 0; j < 4; ++j) {
            __m256d y0 = _mm256_set_pd(y[(j * 4 + 2) * 2 + 1], y[(j * 4 + 2) * 2], y[(j * 4 + 3) * 2 + 1], y[(j * 4 + 3) * 2]);
            __m256d y1 = _mm256_set_pd(y[(j * 4) * 2 + 1], y[(j * 4) * 2], y[(j * 4 + 1) * 2 + 1], y[(j * 4 + 1) * 2]);

            __m256d real = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
            __m256d imag = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);

            for (int k = 0; k < 4; ++k) {
                __m256d a = _mm256_set_pd(x[(i * 4 + k) * 2 + 1], x[(i * 4 + k) * 2], x[(i * 4 + k) * 2 + 1], x[(i * 4 + k) * 2]);
                __m256d c = _mm256_set_pd(y[(k * 4 + j) * 2 + 1], y[(k * 4 + j) * 2], y[(k * 4 + j) * 2 + 1], y[(k * 4 + j) * 2]);
                __m256d b = _mm256_mul_pd(a, _mm256_set_pd(-1.0, 1.0, -1.0, 1.0));
                __m256d d = _mm256_mul_pd(c, _mm256_set_pd(-1.0, 1.0, -1.0, 1.0));

                __m256d prod_real = _mm256_sub_pd(_mm256_mul_pd(a, c), _mm256_mul_pd(b, d));
                __m256d prod_imag = _mm256_add_pd(_mm256_mul_pd(_mm256_add_pd(a, b), c), _mm256_mul_pd(_mm256_sub_pd(a, b), d));

                real = _mm256_add_pd(real, prod_real);
                imag = _mm256_add_pd(imag, prod_imag);
            }

            _mm256_store_pd(&z[(i * 4 + j) * 2], real);
            _mm256_store_pd(&z[(i * 4 + j) * 2 + 1], imag);
        }
    }
}

>>>
Starting program. 2 functions registered.
Segmentation fault
<<<
WA
================================
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    __m256d z_zero = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
    for (int i = 0; i < 32; i += 4) {
        _mm256_store_pd(z + i, z_zero);
    }

    __m256d x_0, x_1, y_0, y_1;
    __m256d prod_real_0, prod_real_1, prod_imag_0, prod_imag_1;
    __m256d sum_real_0 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
    __m256d sum_real_1 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
    __m256d sum_imag_0 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
    __m256d sum_imag_1 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; j += 2) {
            sum_real_0 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
            sum_real_1 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
            sum_imag_0 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);
            sum_imag_1 = _mm256_set_pd(0.0, 0.0, 0.0, 0.0);

            for (int k = 0; k < 4; ++k) {
                x_0 = _mm256_load_pd(x + (i * 4 + k) * 2);
                y_0 = _mm256_load_pd(y + (k * 4 + j) * 2);

                prod_real_0 = _mm256_mul_pd(x_0, y_0);
                prod_imag_0 = _mm256_mul_pd(x_0, y_0);

                x_1 = _mm256_permute4x64_pd(x_0, 0x4E);
                y_1 = _mm256_permute4x64_pd(y_0, 0x4E);

                prod_real_1 = _mm256_mul_pd(x_1, y_1);
                prod_imag_1 = _mm256_mul_pd(x_1, y_1);

                prod_real_0 = _mm256_add_pd(
                    _mm256_sub_pd(_mm256_mul_pd(_mm256_set_pd(2.0, 2.0, 2.0, 2.0), prod_real_0), prod_imag_1),
                    _mm256_mul_pd(_mm256_set_pd(2.0, 2.0, 2.0, 2.0), prod_real_1)
                );
                prod_imag_0 = _mm256_add_pd(
                    _mm256_add_pd(_mm256_mul_pd(_mm256_set_pd(2.0, 2.0, 2.0, 2.0), prod_imag_0), prod_real_1),
                    _mm256_mul_pd(_mm256_set_pd(2.0, 2.0, 2.0, 2.0), prod_imag_1)
                );

                sum_real_0 = _mm256_add_pd(sum_real_0, prod_real_0);
                sum_imag_0 = _mm256_add_pd(sum_imag_0, prod_imag_0);
                sum_real_1 = _mm256_add_pd(sum_real_1, prod_real_1);
                sum_imag_1 = _mm256_add_pd(sum_imag_1, prod_imag_1);
            }

            _mm256_store_pd(z + (i * 4 + j) * 2, sum_real_0);
            _mm256_store_pd(z + (i * 4 + j) * 2 + 1, sum_imag_0);
            _mm256_store_pd(z + (i * 4 + j + 1) * 2, sum_real_1);
            _mm256_store_pd(z + (i * 4 + j + 1) * 2 + 1, sum_imag_1);
        }
    }
}

>>>
Starting program. 2 functions registered.
Segmentation fault
<<<
WA
================================
