Rewrite `slow_performance` into `max_performance`, keeping inputs, outputs, and behavior identical with allowable total squared precision error of 1e-3.  
Only apply performance optimizations (algebraic simplification, cache-friendly memory access, SIMD/AVX-2, loop unrolling, etc.).  

**Assume the code executes on a single core, DO NOT introduce multithreading or parallelism.**

**Target system**
- Intel(R) Core(TM) Ultra 7 265K CPU @ 3.90GHz
- Caches: 240 KB L1 D + 32 KB L1 I per core, 3.00 MB L2 per core, 30 MB shared L3  
- GCC 12 on Debian Bookworm; compile with `-O3 -march=native -mavx2 -std=c++11`

**Hints**
- Write SIMDe code with <immintrin.h> whenever possible.
- Do not use libc functions as their performance is not good.

Return **only** the full, ready-to-compile `max_performance` functionâ€”no other text, comments, or explanations.


```
#include <immintrin.h>
#include "common.h"

void slow_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    for (int i = 0; i < 32; ++i) {
        z[i] = 0.0;
    }

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            double real = 0.0;
            double imag = 0.0;
            for (int k = 0; k < 4; ++k) {
                double a = x[(i * 4 + k) * 2];
                double b = x[(i * 4 + k) * 2 + 1];

                double c = y[(k * 4 + j) * 2];
                double d = y[(k * 4 + j) * 2 + 1];

                double prod_real = 2.0 * a * c - b * d;
                double prod_imag = 2.0 * b * c + 2.0 * a * d;

                real += prod_real;
                imag += prod_imag;
            }

            z[(i * 4 + j) * 2] = real;
            z[(i * 4 + j) * 2 + 1] = imag;
        }
    }
}

void slow_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
}
```


================================
```cpp
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    const __m256i idx_i = _mm256_setr_epi32(0, 1, 2, 3);
    const __m256i idx_j = _mm256_setr_epi32(0, 1, 2, 3);
    const __m256d two = _mm256_set1_pd(2.0);

    __m256d real_vec[4], imag_vec[4];
    real_vec[0] = _mm256_setzero_pd();
    real_vec[1] = _mm256_setzero_pd();
    real_vec[2] = _mm256_setzero_pd();
    real_vec[3] = _mm256_setzero_pd();
    imag_vec[0] = _mm256_setzero_pd();
    imag_vec[1] = _mm256_setzero_pd();
    imag_vec[2] = _mm256_setzero_pd();
    imag_vec[3] = _mm256_setzero_pd();

    for (int k = 0; k < 4; ++k) {
        __m256d a = _mm256_i32gather_pd((const int*)(x + 2 * k), idx_i, 3);
        __m256d b = _mm256_i32gather_pd((const int*)(x + 2 * k + 1), idx_i, 3);

        for (int j = 0; j < 4; ++j) {
            __m256d c = _mm256_i32gather_pd((const int*)(y + 8 * k), idx_j, 4);
            __m256d d = _mm256_i32gather_pd((const int*)(y + 8 * k + 1), idx_j, 4);

            __m256d ac = _mm256_mul_pd(a, c);
            __m256d bd = _mm256_mul_pd(b, d);
            __m256d bc = _mm256_mul_pd(b, c);
            __m256d ad = _mm256_mul_pd(a, d);

            __m256d real_contribution = _mm256_fmadd_pd(ac, two, _mm256_fnmadd_pd(bd, _mm256_set1_pd(1.0), _mm256_setzero_pd()));
            __m256d imag_contribution = _mm256_fmadd_pd(bc, two, _mm256_fmadd_pd(ad, two, _mm256_setzero_pd()));

            real_vec[j] = _mm256_add_pd(real_vec[j], real_contribution);
            imag_vec[j] = _mm256_add_pd(imag_vec[j], imag_contribution);
        }
    }

    for (int j = 0; j < 4; ++j) {
        double real[4];
        double imag[4];
        _mm256_storeu_pd(real, real_vec[j]);
        _mm256_storeu_pd(imag, imag_vec[j]);

        for (int i = 0; i < 4; ++i) {
            int pos = (i * 4 + j) * 2;
            z[pos] = real[i];
            z[pos + 1] = imag[i];
        }
    }
}
```
>>>
make: *** [Makefile:13: benchmark] Error 1
<<<
CE
================================
```cpp
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z)
{
    // Initialize z to zero using AVX
    for (int i = 0; i < 8; ++i) {
        _mm256_storeu_pd(z + 4 * i, _mm256_setzero_pd());
    }

    const int xr0[4] = { 0, 2, 4, 6 };
    const int xi0[4] = { 1, 3, 5, 7 };
    const int xr1[4] = { 8, 10, 12, 14 };
    const int xi1[4] = { 9, 11, 13, 15 };
    const int xr2[4] = { 16, 18, 20, 22 };
    const int xi2[4] = { 17, 19, 21, 23 };
    const int xr3[4] = { 24, 26, 28, 30 };
    const int xi3[4] = { 25, 27, 29, 31 };

#define GATHER_X(I)                                                                                           \
    __m256i xri##I = _mm256_loadu_si256((const __m256i*)(I##_r));                                                \
    __m256i xii##I = _mm256_loadu_si256((const __m256i*)(I##_i));                                                \
    __m256d xa##I = _mm256_i32gather_pd(x, xri##I, 3);                                                          \
    __m256d xb##I = _mm256_i32gather_pd(x, xii##I, 3)

    GATHER_X(0);
    GATHER_X(1);
    GATHER_X(2);
    GATHER_X(3);

#undef GATHER_X

#define HANDLE_IJ(I, J)                                                                                       \
    {                                                                                                           \
        const int yr[4] = { J*2, J*2 +8, J*2 +16, J*2 +24 };                                                     \
        const int yi[4] = { J*2 +1, J*2 +9, J*2 +17, J*2 +25 };                                                 \
        __m256i yri = _mm256_loadu_si256((const __m256i*)yr);                                                   \
        __m256i yii = _mm256_loadu_si256((const __m256i*)yi);                                                   \
        __m256d yc = _mm256_i32gather_pd(y, yri, 3);                                                            \
        __m256d yd = _mm256_i32gather_pd(y, yii, 3);                                                            \
        __m256d two = _mm256_set1_pd(2.0);                                                                      \
        __m256d tmp1 = _mm256_mul_pd(xa##I, two);                                                               \
        tmp1 = _mm256_mul_pd(tmp1, yc);                                                                         \
        __m256d tmp2 = _mm256_mul_pd(xb##I, yd);                                                                \
        __m256d real_per_k = _mm256_sub_pd(tmp1, tmp2);                                                         \
        tmp1 = _mm256_mul_pd(xb##I, two);                                                                       \
        tmp1 = _mm256_mul_pd(tmp1, yc);                                                                         \
        tmp2 = _mm256_mul_pd(xa##I, two);                                                                       \
        tmp2 = _mm256_mul_pd(tmp2, yd);                                                                         \
        __m256d imag_per_k = _mm256_add_pd(tmp1, tmp2);                                                         \
        __m256d sum_real = _mm256_hadd_pd(real_per_k, real_per_k);                                              \
        __m128d sum_half_real = _mm256_extractf128_pd(sum_real, 1);                                             \
        __m128d sum_real128 = _mm_add_sd(_mm256_castpd256_pd128(sum_real), sum_half_real);                      \
        double sr = _mm_cvtsd_f64(sum_real128);                                                                 \
        __m256d sum_imag = _mm256_hadd_pd(imag_per_k, imag_per_k);                                              \
        __m128d sum_half_imag = _mm256_extractf128_pd(sum_imag, 1);                                             \
        __m128d sum_imag128 = _mm_add_sd(_mm256_castpd256_pd128(sum_imag), sum_half_imag);                      \
        double si = _mm_cvtsd_f64(sum_imag128);                                                                 \
        int idx = (I * 4 + J) * 2;                                                                              \
        z[idx] = sr;                                                                                            \
        z[idx + 1] = si;                                                                                        \
    }

    // Handle all 16 combinations of i and j
    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            HANDLE_IJ(i, j)
        }
    }

#undef HANDLE_IJ
}
```
>>>
make: *** [Makefile:13: benchmark] Error 1
<<<
CE
================================
```cpp
#include <immintrin.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, double *__restrict z) {
    for (int i = 0; i < 32; ++i) {
        z[i] = 0.0;
    }

    alignas(32) double yT[4*4*2];
    for (int j = 0; j < 4; ++j) {
        for (int k = 0; k < 4; ++k) {
            int src_idx = (k * 4 + j) * 2;
            int dst_base = j * 4 * 2 + k * 2;
            yT[dst_base] = y[src_idx];
            yT[dst_base + 1] = y[src_idx + 1];
        }
    }

    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            int x_base = i * 8;
            __m256d xr = _mm256_setr_pd(x[x_base], x[x_base + 2], x[x_base + 4], x[x_base + 6]);
            __m256d xi = _mm256_setr_pd(x[x_base + 1], x[x_base + 3], x[x_base + 5], x[x_base + 7]);
            double* y_real_ptr = reinterpret_cast<double*>(&yT[j * 8]);
            double* y_imag_ptr = y_real_ptr + 1;
            __m256d yr = _mm256_loadu_pd(y_real_ptr);
            __m256d yi = _mm256_loadu_pd(y_imag_ptr);

            __m256d two = _mm256_set1_pd(2.0);
            __m256d txa_yr = _mm256_mul_pd(xr, yr);
            __m256d txayi = _mm256_mul_pd(xi, yi);
            __m256d rx = _mm256_sub_pd(_mm256_mul_pd(two, txa_yr), txayi);

            __m256d txiyr = _mm256_mul_pd(xi, yr);
            __m256d txaryi = _mm256_mul_pd(xr, yi);
            __m256d ix = _mm256_add_pd(_mm256_mul_pd(two, txiyr), _mm256_mul_pd(two, txaryi));

            double rsum, isum;
            {
                __m256d sr = rx;
                sr = _mm256_hadd_pd(sr, sr);
                sr = _mm256_hadd_pd(sr, sr);
                double tmp[4];
                _mm256_storeu_pd(tmp, sr);
                rsum = tmp[0];
            }
            {
                __m256d si = ix;
                si = _mm256_hadd_pd(si, si);
                si = _mm256_hadd_pd(si, si);
                double tmp[4];
                _mm256_storeu_pd(tmp, si);
                isum = tmp[0];
            }

            int idx = (i * 4 + j) * 2;
            z[idx] = rsum;
            z[idx + 1] = isum;
        }
    }
}
```
>>>
Starting program. 2 functions registered.
The result of the 2th function is not correct.

Running: slow_performance
55.1094 cycles

Running: max_performance
133.573 cycles
<<<
WA
================================