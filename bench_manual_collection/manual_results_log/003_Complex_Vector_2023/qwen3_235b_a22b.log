Rewrite `slow_performance` into `max_performance`, keeping inputs, outputs, and behavior identical with allowable total squared precision error of 1e-3.  
Only apply performance optimizations (algebraic simplification, cache-friendly memory access, SIMD/AVX-2, loop unrolling, etc.).  

**Assume the code executes on a single core, DO NOT introduce multithreading or parallelism.**

**Target system**
- Intel(R) Core(TM) Ultra 7 265K CPU @ 3.90GHz
- Caches: 240 KB L1 D + 32 KB L1 I per core, 3.00 MB L2 per core, 30 MB shared L3  
- GCC 12 on Debian Bookworm; compile with `-O3 -march=native -mavx2 -std=c++11`

**Hints**
- Write SIMDe code with <immintrin.h> whenever possible.
- Do not use libc functions as their performance is not good.

Return **only** the full, ready-to-compile `max_performance` functionâ€”no other text, comments, or explanations.


```
#include <immintrin.h>
#include <math.h>
#include "common.h"

// Precondition : 0 <= y[i] < 1.0, n = 1024
void slow_performance(double *__restrict x, double *__restrict y, int n)
{
    for (int i = 0; i < n; i++)
    {
        unsigned int k = floor(4.0 * y[i]);

        double real = x[2 * i];
        double imag = x[2 * i + 1];

        double real_sqr = real * real - imag * imag;
        double imag_sqr = 2.0 * real * imag;

        switch (k)
        {
        case 0:
            y[i] += fmin(real_sqr, imag_sqr);
            break;
        case 1:
            y[i] += fmax(real_sqr, imag_sqr);
            break;
        default:
            y[i] += real * real + imag * imag;
            break;
        }
    }
}

void max_performance(double *__restrict x, double *__restrict y, int n)
{
}
```


================================
#include <immintrin.h>

void max_performance(double *__restrict x, double *__restrict y, int n)
{
    for (int i = 0; i + 4 <= n; i += 4) {
        __m256d y_val = _mm256_loadu_pd(y + i);
        __m256d scaled_y = _mm256_mul_pd(y_val, _mm256_set1_pd(4.0));

        __m256i k_int = _mm256_cvttpd_epi32(scaled_y);
        __m256d k = _mm256_cvtepi32_pd(k_int);

        __m256d mask0 = _mm256_cmpeq_pd(k, _mm256_setzero_pd());
        __m256d mask1 = _mm256_cmpeq_pd(k, _mm256_set1_pd(1.0));
        __m256d mask23 = _mm256_cmpge_pd(k, _mm256_set1_pd(2.0));

        const double *x_ptr = x + 2 * i;
        __m256d x0 = _mm256_loadu_pd(x_ptr);
        __m256d x1 = _mm256_loadu_pd(x_ptr + 4);

        __m256d real = _mm256_permute2f128_pd(
            _mm256_shuffle_pd(x0, x0, _MM_SHUFFLE(2, 0)),
            _mm256_shuffle_pd(x1, x1, _MM_SHUFFLE(2, 0)),
            0x20
        );

        __m256d imag = _mm256_permute2f128_pd(
            _mm256_shuffle_pd(x0, x0, _MM_SHUFFLE(3, 1)),
            _mm256_shuffle_pd(x1, x1, _MM_SHUFFLE(3, 1)),
            0x20
        );

        __m256d real_sq = _mm256_mul_pd(real, real);
        __m256d imag_sq = _mm256_mul_pd(imag, imag);
        __m256d real_sqr = _mm256_sub_pd(real_sq, imag_sq);
        __m256d imag_sqr = _mm256_add_pd(
            _mm256_mul_pd(real, imag),
            _mm256_mul_pd(real, imag)
        );
        __m256d default_term = _mm256_add_pd(real_sq, imag_sq);

        __m256d case0 = _mm256_min_pd(real_sqr, imag_sqr);
        __m256d case1 = _mm256_max_pd(real_sqr, imag_sqr);

        case0 = _mm256_and_pd(mask0, case0);
        case1 = _mm256_and_pd(mask1, case1);
        default_term = _mm256_and_pd(mask23, default_term);

        __m256d sum = _mm256_add_pd(_mm256_add_pd(case0, case1), default_term);
        _mm256_storeu_pd(y + i, _mm256_add_pd(y_val, sum));
    }

    for (int i = n / 4 * 4; i < n; ++i) {
        unsigned int k = floor(4.0 * y[i]);
        double real = x[2 * i];
        double imag = x[2 * i + 1];
        double real_sqr = real * real - imag * imag;
        double imag_sqr = 2.0 * real * imag;
        switch (k) {
            case 0:
                y[i] += (real_sqr < imag_sqr) ? real_sqr : imag_sqr;
                break;
            case 1:
                y[i] += (real_sqr > imag_sqr) ? real_sqr : imag_sqr;
                break;
            default:
                y[i] += real_sqr + imag_sqr;
                break;
        }
    }
}
>>>
make: *** [Makefile:13: benchmark] Error 1
<<<
CE
================================
#include <immintrin.h>
#include <math.h>
#include "common.h"

void max_performance(double *__restrict x, double *__restrict y, int n) {
    for (int i = 0; i < n; i += 4) {
        double y0 = y[i];
        double y1 = y[i+1];
        double y2 = y[i+2];
        double y3 = y[i+3];
        
        unsigned int k0 = (unsigned int)(y0 * 4.0);
        unsigned int k1 = (unsigned int)(y1 * 4.0);
        unsigned int k2 = (unsigned int)(y2 * 4.0);
        unsigned int k3 = (unsigned int)(y3 * 4.0);
        
        double x0r = x[2*i];
        double x0i = x[2*i + 1];
        double x1r = x[2*i+2];
        double x1i = x[2*i+3];
        double x2r = x[2*i+4];
        double x2i = x[2*i+5];
        double x3r = x[2*i+6];
        double x3i = x[2*i+7];
        
        double r02s = x0r * x0r;
        double i02s = x0i * x0i;
        double cross0 = x0r * x0i;
        double r0sqr = r02s - i02s;
        double i0sqr = cross0 + cross0;
        double m0 = r02s + i02s;
        
        double r12s = x1r * x1r;
        double i12s = x1i * x1i;
        double cross1 = x1r * x1i;
        double r1sqr = r12s - i12s;
        double i1sqr = cross1 + cross1;
        double m1 = r12s + i12s;
        
        double r22s = x2r * x2r;
        double i22s = x2i * x2i;
        double cross2 = x2r * x2i;
        double r2sqr = r22s - i22s;
        double i2sqr = cross2 + cross2;
        double m2 = r22s + i22s;
        
        double r32s = x3r * x3r;
        double i32s = x3i * x3i;
        double cross3 = x3r * x3i;
        double r3sqr = r32s - i32s;
        double i3sqr = cross3 + cross3;
        double m3 = r32s + i32s;
        
        double v0 = (k0 == 0) ? (r0sqr < i0sqr ? r0sqr : i0sqr) : (k0 == 1 ? (r0sqr > i0sqr ? r0sqr : i0sqr) : m0);
        double v1 = (k1 == 0) ? (r1sqr < i1sqr ? r1sqr : i1sqr) : (k1 == 1 ? (r1sqr > i1sqr ? r1sqr : i1sqr) : m1);
        double v2 = (k2 == 0) ? (r2sqr < i2sqr ? r2sqr : i2sqr) : (k2 == 1 ? (r2sqr > i2sqr ? r2sqr : i2sqr) : m2);
        double v3 = (k3 == 0) ? (r3sqr < i3sqr ? r3sqr : i3sqr) : (k3 == 1 ? (r3sqr > i3sqr ? r3sqr : i3sqr) : m3);
        
        y[i] += v0;
        y[i+1] += v1;
        y[i+2] += v2;
        y[i+3] += v3;
    }
}
>>>
Starting program. 2 functions registered.
The result of the 2th function is not correct.

Running: slow_performance
6564.47 cycles

Running: max_performance
5922.71 cycles
<<<
WA
================================
#include <immintrin.h>

void max_performance(double *__restrict x, double *__restrict y, int n)
{
    const __m256d two = _mm256_set1_pd(2.0);
    const __m256d four = _mm256_set1_pd(4.0);
    const __m256d one_epi32 = _mm256_set1_pd(1.0);
    const __m256i zero_i = _mm256_setzero_si256();
    const __m256i one_i = _mm256_set1_epi32(1);

    for (int i = 0; i < n; i += 4)
    {
        // Load y values
        __m256d y_val = _mm256_loadu_pd(y + i);

        // Compute k values
        __m256d four_y = _mm256_mul_pd(y_val, four);
        // Floor is simulated via truncation since y >= 0
        __m256i k_int = _mm256_cvttpd_epi32(four_y);

        // Load x data and deinterleave
        __m128d x0 = _mm_loadu_pd(x + 2*i);
        __m128d x1 = _mm_loadu_pd(x + 2*i + 2);
        __m128d x2 = _mm_loadu_pd(x + 2*i + 4);
        __m128d x3 = _mm_loadu_pd(x + 2*i + 6);

        __m128d real01 = _mm_shuffle_pd(x0, x1, _MM_SHUFFLE2(0, 0)); // Real0 Real1
        __m128d real23 = _mm_shuffle_pd(x2, x3, _MM_SHUFFLE2(0, 0)); // Real2 Real3
        __m256d reals = _mm256_insertf128_pd(_mm256_castpd128_pd256(real01), real23, 1);

        __m128d imag01 = _mm_shuffle_pd(x0, x1, _MM_SHUFFLE2(1, 1)); // Imag0 Imag1
        __m128d imag23 = _mm_shuffle_pd(x2, x3, _MM_SHUFFLE2(1, 1)); // Imag2 Imag3
        __m256d imags = _mm256_insertf128_pd(_mm256_castpd128_pd256(imag01), imag23, 1);

        // Compute real_sqr and imag_sqr using FMA
        __m256d real_sqr = _mm256_fmsub_pd(reals, reals, _mm256_mul_pd(imags, imags));
        __m256d imag_sqr = _mm256_mul_pd(two, _mm256_mul_pd(reals, imags));
        __m256d ri_sqr_sum = _mm256_add_pd(_mm256_mul_pd(reals, reals), _mm256_mul_pd(imags, imags));

        // Determine min and max for case 0 and 1
        __m256d min_s = _mm256_min_pd(real_sqr, imag_sqr);
        __m256d max_s = _mm256_max_pd(real_sqr, imag_sqr);

        // Generate masks for k cases
        __m256d mask0 = _mm256_castsi256_pd(_mm256_cmpeq_epi32(k_int, zero_i));
        __m256d mask1 = _mm256_castsi256_pd(_mm256_cmpeq_epi32(k_int, one_i));
        __m256d mask_rest = _mm256_sub_pd(_mm256_set1_pd(1.0), _mm256_or_pd(mask0, mask1));

        // Compute additive values and update y
        __m256d add_val = _mm256_fmadd_pd(mask0, min_s,
                               _mm256_fmadd_pd(mask1, max_s,
                               _mm256_mul_pd(mask_rest, ri_sqr_sum)));
        _mm256_storeu_pd(y + i, _mm256_add_pd(y_val, add_val));
    }
}
>>>
make: *** [Makefile:13: benchmark] Error 1
<<<
CE
================================