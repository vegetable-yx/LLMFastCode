Rewrite `slow_performance` into `max_performance`, keeping inputs, outputs, and behavior identical with allowable total squared precision error of 1e-3.  
Only apply performance optimizations (algebraic simplification, cache-friendly memory access, SIMD/AVX-2, loop unrolling, etc.).  

**Assume the code executes on a single core, DO NOT introduce multithreading or parallelism.**

**Target system**
- Intel(R) Core(TM) Ultra 7 265K CPU @ 3.90GHz
- Caches: 240 KB L1 D + 32 KB L1 I per core, 3.00 MB L2 per core, 30 MB shared L3  
- GCC 12 on Debian Bookworm; compile with `-O3 -march=native -mavx2 -std=c++11`

**Hints**
- Write SIMDe code with <immintrin.h> whenever possible.
- Do not use libc functions as their performance is not good.

Return **only** the full, ready-to-compile `max_performance` functionâ€”no other text, comments, or explanations.


```
void slow_performance1(double *__restrict x, double *__restrict y)
{
    for (int i = 0; i < 4; i++)
    {
        for (int j = 0; j < 4; j++)
        {
            y[i * 8 + j * 2] = x[j * 8 + i * 2];
            y[i * 8 + j * 2 + 1] = -x[j * 8 + i * 2 + 1];
        }
    }
}

void max_performance(double *__restrict x, double *__restrict y)
{
}
```


================================
#include <immintrin.h>

void max_performance(double *__restrict x, double *__restrict y) {
    __m256d xmm0, xmm1;
    for (int i = 0; i < 4; ++i) {
        for (int j = 0; j < 4; ++j) {
            xmm0 = _mm256_loadu_pd(x + j * 8 + i * 2);
            xmm1 = _mm256_lddqu_pd(x + j * 8 + i * 2 + 1);
            _mm256_storeu_pd(y + i * 8 + j * 2, xmm0);
            xmm1 = _mm256_xor_pd(xmm1, _mm256_set1_pd(-1.0));
            _mm256_storeu_pd(y + i * 8 + j * 2 + 1, xmm1);
        }
    }
}
>>>
make: *** [Makefile:13: benchmark] Error 1
<<<
CE
================================
#include <immintrin.h>

void max_performance(double *__restrict x, double *__restrict y) {
    __m256d xmm0, xmm1;
    double* x_ptr;
    double* y_ptr;
    for (int i = 0; i < 4; i++) {
        x_ptr = &x[i * 2];
        y_ptr = &y[i * 8];
        for (int j = 0; j < 4; j++) {
            xmm0 = _mm256_loadu_pd(x_ptr);
            xmm1 = _mm256_setr_pd(1.0, -1.0, 1.0, -1.0);
            xmm0 = _mm256_mul_pd(xmm0, xmm1);
            _mm256_storeu_pd(y_ptr, xmm0);
            x_ptr += 8;
            y_ptr += 2;
        }
    }
}
>>>
Starting program. 2 functions registered.
The result of the 2th function is not correct.

Running: slow_performance1
26.4601 cycles
Segmentation fault
<<<
WA
================================
#include <immintrin.h>

void max_performance(double *__restrict x, double *__restrict y) {
    __m256d xmm0, xmm1;
    for (int i = 0; i < 4; i++) {
        for (int j = 0; j < 4; j++) {
            xmm0 = _mm256_loadu_pd(x + j * 8 + i * 2);
            xmm1 = _mm256_loadu_pd(x + j * 8 + i * 2 + 2);
            _mm256_storeu_pd(y + i * 8 + j * 2, xmm0);
            _mm256_storeu_pd(y + i * 8 + j * 2 + 2, xmm1);
            xmm0 = _mm256_loadu_pd(x + j * 8 + i * 2 + 4);
            xmm1 = _mm256_loadu_pd(x + j * 8 + i * 2 + 6);
            _mm256_storeu_pd(y + i * 8 + j * 2 + 4, xmm0);
            _mm256_storeu_pd(y + i * 8 + j * 2 + 6, xmm1);

            xmm0 = _mm256_loadu_pd(x + j * 8 + i * 2 + 1);
            xmm0 = _mm256_mul_pd(xmm0, _mm256_set1_pd(-1.0));
            xmm1 = _mm256_loadu_pd(x + j * 8 + i * 2 + 3);
            xmm1 = _mm256_mul_pd(xmm1, _mm256_set1_pd(-1.0));
            _mm256_storeu_pd(y + i * 8 + j * 2 + 1, xmm0);
            _mm256_storeu_pd(y + i * 8 + j * 2 + 3, xmm1);
            xmm0 = _mm256_loadu_pd(x + j * 8 + i * 2 + 5);
            xmm0 = _mm256_mul_pd(xmm0, _mm256_set1_pd(-1.0));
            xmm1 = _mm256_loadu_pd(x + j * 8 + i * 2 + 7);
            xmm1 = _mm256_mul_pd(xmm1, _mm256_set1_pd(-1.0));
            _mm256_storeu_pd(y + i * 8 + j * 2 + 5, xmm0);
            _mm256_storeu_pd(y + i * 8 + j * 2 + 7, xmm1);
        }
    }
}
>>>
Starting program. 2 functions registered.
The result of the 2th function is not correct.

Running: slow_performance1
26.5341 cycles
Segmentation fault
<<<
WA
================================